{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T17:53:01.434149Z",
     "start_time": "2021-02-12T17:53:01.429176Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import svm, neighbors\n",
    "\n",
    "from sklearn import metrics\n",
    "from math import log\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "# Import all lib to create benchmark functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The differents models are created with the same pattern\n",
    " - Function with no arg\n",
    " - Grid param in the body function -> Grid Search CV in Benchmark Notebook\n",
    " - Return a dictionnary with model name, model function, grid param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèle 0 : Dummy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T10:21:23.619869Z",
     "start_time": "2021-02-12T10:21:23.599146Z"
    }
   },
   "outputs": [],
   "source": [
    "def dum():\n",
    "    grid_param0 = {\n",
    "        'dummy__strategy': ['most_frequent']   \n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'model_name': 'dummy',\n",
    "        'model': DummyClassifier(),\n",
    "        'param': grid_param0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèle 1 : Forêt aléatoire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T10:24:05.464350Z",
     "start_time": "2021-02-12T10:24:05.443686Z"
    }
   },
   "outputs": [],
   "source": [
    "def ran_for(n_estim, crit):\n",
    "    grid_param1 = {\n",
    "        'random_forest__n_estimators': n_estim,\n",
    "        'random_forest__criterion': crit,        \n",
    "#        'random_forest__max_depth': d,\n",
    "#        'random_forest__max_features': f,\n",
    "#        'random_forest__min_samples_leaf': leaf,\n",
    "#        'random_forest__min_impurity_decrease': i\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'model_name': 'random_forest',\n",
    "        'model': RandomForestClassifier(),\n",
    "        'param': grid_param1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèle 2 : GradientBoosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T10:42:57.898366Z",
     "start_time": "2021-02-12T10:42:57.884943Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_boo(loss, lr, n_estim):\n",
    "    grid_param2 = {\n",
    "        'gradient_boosting__loss': loss,\n",
    "        'gradient_boosting__learning_rate': lr,\n",
    "        'gradient_boosting__n_estimators': n_estim,\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'model_name': 'gradient_boosting',\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'param': grid_param2\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèle 3 : XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T10:43:01.441739Z",
     "start_time": "2021-02-12T10:43:01.436215Z"
    }
   },
   "outputs": [],
   "source": [
    "def xg_boo(n_estim, booster):\n",
    "    grid_param3 = {\n",
    "        'xgboost__n_estimators': n_estim,\n",
    "        'xgboost__booster': booster\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'model_name': 'xgboost',\n",
    "        'model': xgb.XGBClassifier(),\n",
    "        'param': grid_param3\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèle 4 : KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T10:46:20.967368Z",
     "start_time": "2021-02-12T10:46:20.958392Z"
    }
   },
   "outputs": [],
   "source": [
    "def knn(n_neigh, weight):\n",
    "    grid_param4 = {\n",
    "        'knn__n_neighbors': n_neigh,\n",
    "        'knn__weights': weight,\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'model_name': 'knn',\n",
    "        'model': neighbors.KNeighborsClassifier(),\n",
    "        'param': grid_param4\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèle 5 : SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T10:57:21.663993Z",
     "start_time": "2021-02-12T10:57:21.655003Z"
    }
   },
   "outputs": [],
   "source": [
    "def svc(penalty, loss):\n",
    "    grid_param5 = {\n",
    "        'svc__penalty': penalty,\n",
    "        'svc__loss': loss,\n",
    "        'svc__multi_class': ['crammer_singer']\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'model_name': 'svc',\n",
    "        'model': svm.LinearSVC(),\n",
    "        'param': grid_param5\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modèle 6 : SVC (kernel version)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T10:57:41.070577Z",
     "start_time": "2021-02-12T10:57:41.053842Z"
    }
   },
   "outputs": [],
   "source": [
    "def svc_kern(c, kern):\n",
    "    grid_param6 = {\n",
    "        'svc_kernel__C': c,\n",
    "        'svc_kernel__kernel': kern,\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'model_name': 'svc_kernel',\n",
    "        'model': svm.SVC(),\n",
    "        'param': grid_param6\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmark des modèles crées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T18:19:20.253309Z",
     "start_time": "2021-02-12T18:19:20.231006Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_benchmark(x, y, scal, models):\n",
    "    \"\"\"Function to compare a list of model with a dataset\n",
    "\n",
    "    Args :\n",
    "    x : arrays or pd.dataFrame\n",
    "    y : one dimension array or pd.Series\n",
    "    scal : none, norm or log may be put in argument \n",
    "           -> scale dataset\n",
    "    models : a list of model included in the model_benchmark could be chose\n",
    "\n",
    "    Return : \n",
    "    a dataframe with best param, mse and r square for each model tested\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a dF to stock results of each model by column\n",
    "    model_performance = pd.DataFrame(dtype='float64')\n",
    "\n",
    "    # List to stock param of each model\n",
    "    param = []\n",
    "    elaps_time = []\n",
    "    yt = []\n",
    "    yp = []\n",
    "\n",
    "    # Split data in train and test\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "        x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Define the scaler\n",
    "    std_scale = preprocessing.StandardScaler()\n",
    "    normalizer = preprocessing.Normalizer(norm='l2')  # fit does nothing\n",
    "\n",
    "    for i in models:\n",
    "        model = i\n",
    "\n",
    "        # Start timer\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        # Scaling operation within the pipeline selected in arg\n",
    "        if scal == 'standard':\n",
    "            pipe = pipeline.Pipeline(steps=[('scaler', std_scale),\n",
    "                                            (i['model_name'], i['model'])])\n",
    "        elif scal == 'normal':\n",
    "            pipe = pipeline.Pipeline(steps=[('norm', normalizer),\n",
    "                                            (i['model_name'], i['model'])])\n",
    "\n",
    "        # Grid search with pipeline and grid param in each model function\n",
    "        grids = model_selection.GridSearchCV(\n",
    "            pipe, i['param'], cv=7)\n",
    "\n",
    "        # Fit the model / then predict y value\n",
    "        grids.fit(x_train, y_train)\n",
    "        y_pred = grids.predict(x_test)\n",
    "\n",
    "        # Time stop\n",
    "        time_stop = timeit.default_timer() - start_time\n",
    "\n",
    "        # Best params in training\n",
    "        param.append([i['model_name'], grids.best_params_])\n",
    "        yt.append([i['model_name'], y_test])\n",
    "        yp.append([i['model_name'], y_pred])\n",
    "        elaps_time.append([i['model_name'], str(time_stop)])\n",
    "\n",
    "        # Scoring\n",
    "        train_accuracy = (grids.best_score_)\n",
    "        test_accuracy = (metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "        # Create a dF to display all the score results obtained by ML model\n",
    "        model_serie = pd.DataFrame(\n",
    "            {\n",
    "                i['model_name']: [\n",
    "                    train_accuracy.round(3),\n",
    "                    test_accuracy.round(3),\n",
    "                    time_stop\n",
    "                ]\n",
    "            },\n",
    "            index=['Train Accuracy', 'Test Accuracy', 'Time'],\n",
    "            dtype='float64')\n",
    "        \n",
    "        model_performance = pd.concat([model_serie, model_performance], axis=1)\n",
    "\n",
    "        # Check progression of the model fitted during running of the function\n",
    "        print(\"{} is trained and fitted in {:.3f} sec\".format(\n",
    "            i['model_name'], time_stop))\n",
    "\n",
    "    # Output dict\n",
    "    return {\n",
    "        'set': type(y),\n",
    "        'perf': model_performance,\n",
    "        'param': param,\n",
    "        'time': elaps_time,\n",
    "        'yt': yt,\n",
    "        'yp': yp\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
